{% load static %}
<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="stylesheet" href={% static 'css/articleaiStyling.css' %}>
    <title>Introduction to CSS</title>
</head>
<body>
        <header>
            <nav>
                <a href="html/introtohtml.html"> introduction to HTML</a>
                <a href="css/introduction.html"> introduction to CSS</a>
            </nav>

            <h1>Artificial Intelligence and the Future of Humans</h1>
            <h2>Experts say the rise of artificial intelligence will make most people better off over the next decade,
                but many have concerns about how advances in AI will affect what it means to be human, to be productive
                and to exercise free will
            </h2>
            <section id="copyWrite">By Janna Anderson and Lee Rainie<br/></section>

            <img src="{% static 'images/aiTechnology.webp' %}" class="staticPic"/>
        </header>
        <main>
            <article>
                <section id="copyWrite">A vehicle and person recognition system for use by law enforcement is demonstrated at
                    last year’s GPU Technology Conference in Washington, D.C., which highlights new uses for artificial intelligence
                    and deep learning. (Saul Loeb/AFP/Getty Images)</section>
                <aside>
                    <p>
                        Digital life is augmenting human capacities and disrupting eons-old human activities. Code-driven systems have
                        spread to more than half of the world’s inhabitants in ambient information and connectivity, offering previously
                        unimagined opportunities and unprecedented threats. As emerging algorithm-driven artificial intelligence (AI)
                        continues to spread, will people be better off than they are today?
                    </p>
                </aside>
                <aside>
                    <p>
                        Some 979 technology pioneers, innovators, developers, business and policy leaders, researchers and
                        activists answered this question in a canvassing of experts conducted in the summer of 2018.
                    </p>
                </aside>
                <div class="wrapper">
                    <p>
                        The experts predicted networked artificial intelligence will amplify human effectiveness but also threaten human
                        autonomy, agency and capabilities. They spoke of the wide-ranging possibilities; that computers might match or even
                        exceed human intelligence and capabilities on tasks such as complex decision-making, reasoning and learning,
                        sophisticated analytics and pattern recognition, visual acuity, speech recognition and language translation.
                        They said “smart” systems in communities, in vehicles, in buildings and utilities, on farms and in business
                        processes will save time, money and lives and offer opportunities for individuals to enjoy a more-customized future.
                    </p>
                </div>
                <p>
                    Many focused their optimistic remarks on health care and the many possible applications of AI in diagnosing and
                    treating patients or helping senior citizens live fuller and healthier lives. They were also enthusiastic about
                    AI’s role in contributing to broad public-health programs built around massive amounts of data that may be captured
                    in the coming years about everything from personal genomes to nutrition. Additionally, a number of these experts
                    predicted that AI would abet long-anticipated changes in formal and informal education systems.
                </p>
                <p>
                    Yet, most experts, regardless of whether they are optimistic or not, expressed concerns about the long-term impact
                    of these new tools on the essential elements of being human. All respondents in this non-scientific canvassing were
                    asked to elaborate on why they felt AI would leave people better off or not. Many shared deep worries, and many
                    also suggested pathways toward solutions. The main themes they sounded about threats and remedies are outlined
                    in the accompanying table.
                </p>
                <p>
                    [chart id=”21972″] <br/>
                    Specifically, participants were asked to consider the following:<br/><br/>
                    <div class="quotation">
                        “Please think forward to the year 2030. Analysts expect that people will become even more dependent on networked
                        artificial intelligence (AI) in complex digital systems. Some say we will continue on the historic arc of
                        augmenting our lives with mostly positive results as we widely implement these networked tools. Some say our
                        increasing dependence on these AI and related systems is likely to lead to widespread difficulties.<br/><br/>

                        Our question: By 2030, do you think it is most likely that advancing AI and related technology systems will
                        enhance human capacities and empower them? That is, most of the time, will most people be better off than they are
                        today? Or is it most likely that advancing AI and related technology systems will lessen human autonomy and agency
                        to such an extent that most people will not be better off than the way things are today?”
                    </div>
                </p>
                <p>
                    Overall, and despite the downsides they fear, <b>63%</b> of respondents in this canvassing said they are hopeful that
                    most individuals will be mostly better off in 2030, and 37% said people will not be better off.<br/><br/>
                    A number of the thought leaders who participated in this canvassing said humans’ expanding reliance on
                    technological systems will only go well if close attention is paid to how these tools, platforms and networks are
                    engineered, distributed and updated. Some of the powerful, overarching answers included those from:<br/><br/>

                    <b>Sonia Katyal</b>, co-director of the Berkeley Center for Law and Technology and a member of the inaugural U.S.
                    Commerce Department Digital Economy Board of Advisors, predicted, “In 2030, the greatest set of questions will
                    involve how perceptions of AI and their application will influence the trajectory of civil rights in the future.
                    Questions about privacy, speech, the right of assembly and technological construction of personhood will all
                    re-emerge in this new AI context, throwing into question our deepest-held beliefs about equality and opportunity
                    for all. Who will benefit and who will be disadvantaged in this new world depends on how broadly we analyze these
                    questions today, for the future.”<br/><br/>

                    <b>Erik Brynjolfsson</b>, director of the MIT Initiative on the Digital Economy and author of “Machine, Platform,
                    Crowd: Harnessing Our Digital Future,” said, “AI and related technologies have already achieved superhuman
                    performance in many areas, and there is little doubt that their capabilities will improve, probably very
                    significantly, by 2030. … I think it is more likely than not that we will use this power to make the world a better
                    place. For instance, we can virtually eliminate global poverty, massively reduce disease and provide better
                    education to almost everyone on the planet. That said, AI and ML [machine learning] can also be used to increasingly
                    concentrate wealth and power, leaving many people behind, and to create even more horrifying weapons. Neither
                    outcome is inevitable, so the right question is not ‘What will happen?’ but ‘What will we choose to do?’ We need
                    to work aggressively to make sure technology matches our values. This can and must be done at all levels, from
                    government, to business, to academia, and to individual choices.”<br/><br/>

                    <b>Bryan Johnson</b>, founder and CEO of Kernel, a leading developer of advanced neural interfaces, and OS Fund,
                    a venture capital firm, said, “I strongly believe the answer depends on whether we can shift our economic systems
                    toward prioritizing radical human improvement and staunching the trend toward human irrelevance in the face of AI.
                    I don’t mean just jobs; I mean true, existential irrelevance, which is the end result of not prioritizing human
                    well-being and cognition.”<br/><br/>

                    <b>Marina Gorbis</b>, executive director of the Institute for the Future, said, “Without significant changes in
                    our political economy and data governance regimes [AI] is likely to create greater economic inequalities, more
                    surveillance and more programmed and non-human-centric interactions. Every time we program our environments, we end
                    up programming ourselves and our interactions. Humans have to become more standardized, removing serendipity and
                    ambiguity from our interactions. And this ambiguity and complexity is what is the essence of being human.”<br/><br/>

                    <b>Judith Donath</b>, author of “The Social Machine, Designs for Living Online” and faculty fellow at Harvard
                    University’s Berkman Klein Center for Internet & Society, commented, “By 2030, most social situations will be
                    facilitated by bots – intelligent-seeming programs that interact with us in human-like ways. At home, parents will
                    engage skilled bots to help kids with homework and catalyze dinner conversations. At work, bots will run meetings.
                    A bot confidant will be considered essential for psychological well-being, and we’ll increasingly turn to such
                    companions for advice ranging from what to wear to whom to marry. We humans care deeply about how others see us –
                    and the others whose approval we seek will increasingly be artificial. By then, the difference between humans and
                    bots will have blurred considerably. Via screen and projection, the voice, appearance and behaviors of bots will be
                    indistinguishable from those of humans, and even physical robots, though obviously non-human, will be so
                    convincingly sincere that our impression of them as thinking, feeling beings, on par with or superior to ourselves,
                    will be unshaken. Adding to the ambiguity, our own communication will be heavily augmented: Programs will compose
                    many of our messages and our online/AR appearance will [be] computationally crafted. (Raw, unaided human speech
                    and demeanor will seem embarrassingly clunky, slow and unsophisticated.) Aided by their access to vast troves of
                    data about each of us, bots will far surpass humans in their ability to attract and persuade us. Able to mimic
                    emotion expertly, they’ll never be overcome by feelings: If they blurt something out in anger, it will be because
                    that behavior was calculated to be the most efficacious way of advancing whatever goals they had ‘in mind.’ But
                    what are those goals? Artificially intelligent companions will cultivate the impression that social goals similar
                    to our own motivate them – to be held in good regard, whether as a beloved friend, an admired boss, etc. But their
                    real collaboration will be with the humans and institutions that control them. Like their forebears today, these
                    will be sellers of goods who employ them to stimulate consumption and politicians who commission them to sway
                    opinions.”<br/><br/>

                    <b>Andrew McLaughlin</b>, executive director of the Center for Innovative Thinking at Yale University, previously
                    deputy chief technology officer of the United States for President Barack Obama and global public policy lead for
                    Google, wrote, “2030 is not far in the future. My sense is that innovations like the internet and networked AI have
                    massive short-term benefits, along with long-term negatives that can take decades to be recognizable. AI will drive
                    a vast range of efficiency optimizations but also enable hidden discrimination and arbitrary penalization of
                    individuals in areas like insurance, job seeking and performance assessment.”<br/><br/>

                    <b>Michael M. Roberts</b>, first president and CEO of the Internet Corporation for Assigned Names and Numbers
                    (ICANN) and Internet Hall of Fame member, wrote, “The range of opportunities for intelligent agents to augment
                    human intelligence is still virtually unlimited. The major issue is that the more convenient an agent is, the more
                    it needs to know about you – preferences, timing, capacities, etc. – which creates a tradeoff of more help requires
                    more intrusion. This is not a black-and-white issue – the shades of gray and associated remedies will be argued
                    endlessly. The record to date is that convenience overwhelms privacy. I suspect that will continue.”<br/><br/>

                    <b>danah boyd</b>, a principal researcher for Microsoft and founder and president of the Data & Society Research
                    Institute, said, “AI is a tool that will be used by humans for all sorts of purposes, including in the pursuit of
                    power. There will be abuses of power that involve AI, just as there will be advances in science and humanitarian
                    efforts that also involve AI. Unfortunately, there are certain trend lines that are likely to create massive
                    instability. Take, for example, climate change and climate migration. This will further destabilize Europe and
                    the U.S., and I expect that, in panic, we will see AI be used in harmful ways in light of other geopolitical
                    crises.”<br/><br/>

                    <b>Amy Webb,</b> founder of the Future Today Institute and professor of strategic foresight at New York University,
                    commented, “The social safety net structures currently in place in the U.S. and in many other countries around the
                    world weren’t designed for our transition to AI. The transition through AI will last the next 50 years or more. As
                    we move farther into this third era of computing, and as every single industry becomes more deeply entrenched with
                    AI systems, we will need new hybrid-skilled knowledge workers who can operate in jobs that have never needed to
                    exist before. We’ll need farmers who know how to work with big data sets. Oncologists trained as robotocists.
                    Biologists trained as electrical engineers. We won’t need to prepare our workforce just once, with a few changes
                    to the curriculum. As AI matures, we will need a responsive workforce, capable of adapting to new processes,
                    systems and tools every few years. The need for these fields will arise faster than our labor departments, schools
                    and universities are acknowledging. It’s easy to look back on history through the lens of present – and to overlook
                    the social unrest caused by widespread technological unemployment. We need to address a difficult truth that few
                    are willing to utter aloud: AI will eventually cause a large number of people to be permanently out of work. Just
                    as generations before witnessed sweeping changes during and in the aftermath of the Industrial Revolution, the
                    rapid pace of technology will likely mean that Baby Boomers and the oldest members of Gen X – especially those
                    whose jobs can be replicated by robots – won’t be able to retrain for other kinds of work without a significant
                    investment of time and effort.” <br/><br/>

                    <b>Barry Chudakov,</b> founder and principal of Sertain Research, commented, “By 2030 the human-machine/AI
                    collaboration will be a necessary tool to manage and counter the effects of multiple simultaneous accelerations:
                    broad technology advancement, globalization, climate change and attendant global migrations. In the past, human
                    societies managed change through gut and intuition, but as Eric Teller, CEO of Google X, has said, ‘Our societal
                    structures are failing to keep pace with the rate of change.’ To keep pace with that change and to manage a growing
                    list of ‘wicked problems’ by 2030, AI – or using Joi Ito’s phrase,
                    <a  href="https://pubpub.ito.com/pub/extended-intelligence/release/1">extended intelligence</a> – will value and revalue
                    virtually every area of human behavior and interaction. AI and advancing technologies will change our response
                    framework and time frames (which in turn, changes our sense of time). Where once social interaction happened in
                    places – work, school, church, family environments – social interactions will increasingly happen in continuous,
                    simultaneous time. If we are fortunate, we will follow the
                    <a href="https://futureoflife.org/open-letter/ai-principles/">23 Asilomar AI Principles outlined by the Future of
                    Life Institute</a> and will work toward ‘not undirected intelligence but beneficial intelligence.’ Akin to nuclear
                    deterrence stemming from mutually assured destruction, AI and related technology systems constitute a force for
                    a moral renaissance. We must embrace that moral renaissance, or we will face moral conundrums that could bring
                    about human demise. … My greatest hope for human-machine/AI collaboration constitutes a moral and ethical
                    renaissance – we adopt a moonshot mentality and lock arms to prepare for the accelerations coming at us.
                    My greatest fear is that we adopt the logic of our emerging technologies – instant response, isolation behind
                    screens, endless comparison of self-worth, fake self-presentation – without thinking or responding smartly.”<br/><br/>

                    <b>John C. Havens,</b> executive director of the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems
                    and the Council on Extended Intelligence, wrote, “Now, in 2018, a majority of people around the world can’t access
                    their data, so any ‘human-AI augmentation’ discussions ignore the critical context of who actually controls people’s
                    information and identity. Soon it will be extremely difficult to identify any autonomous or intelligent systems
                    whose algorithms don’t interact with human data in one form or another.”<br/><br/>

                    At stake is nothing less than what sort of society we want to live in and how we experience our humanity.Batya
                    Friedman <br/>
                    Batya Friedman<br/><br/>

                    <b>Batya Friedman,</b> a human-computer interaction professor at the University of Washington’s Information School, wrote,
                    “Our scientific and technological capacities have and will continue to far surpass our moral ones – that is our
                    ability to use wisely and humanely the knowledge and tools that we develop. … Automated warfare – when autonomous
                    weapons kill human beings without human engagement – can lead to a lack of responsibility for taking the enemy’s
                    life or even knowledge that an enemy’s life has been taken. At stake is nothing less than what sort of society we
                    want to live in and how we experience our humanity.”<br/><br/>

                </p>
            </article>
        </main>




</body>
<footer><a href=" https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/">
    to read more about</a>
</footer>
</html>